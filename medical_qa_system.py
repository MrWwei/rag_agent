"""
åŒ»ç–—é—®ç­”ç³»ç»Ÿ
ç»“åˆRAGæ£€ç´¢å’Œå¤§æ¨¡å‹ï¼Œæä¾›ä¸“ä¸šçš„åŒ»ç–—é—®ç­”æœåŠ¡
"""

import os
import json
from typing import List, Dict, Any, Optional
from openai import OpenAI
from src.rag_retriever import MedicalRAGRetriever


class MedicalQASystem:
    """åŒ»ç–—é—®ç­”ç³»ç»Ÿ"""
    
    def __init__(self, 
                 vector_store_path: str = "./vector_store",
                 model: str = "qwen-plus",
                 max_context_length: int = 4000,
                 enable_rag: bool = True):
        """
        åˆå§‹åŒ–åŒ»ç–—é—®ç­”ç³»ç»Ÿ
        
        Args:
            vector_store_path: å‘é‡å­˜å‚¨è·¯å¾„
            model: ä½¿ç”¨çš„å¤§æ¨¡å‹åç§°
            max_context_length: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
            enable_rag: æ˜¯å¦å¯ç”¨RAGæ£€ç´¢ï¼ŒFalseåˆ™ä½¿ç”¨çº¯å¤§æ¨¡å‹æ¨¡å¼
        """
        self.vector_store_path = vector_store_path
        self.model = model
        self.max_context_length = max_context_length
        self.enable_rag = enable_rag
        
        # æ ¹æ®RAGå¼€å…³å†³å®šæ˜¯å¦åˆå§‹åŒ–RAGæ£€ç´¢å™¨
        if self.enable_rag:
            self.retriever = MedicalRAGRetriever(vector_store_path)
        else:
            self.retriever = None
            print("ğŸ”„ RAGæ£€ç´¢å·²å…³é—­ï¼Œä½¿ç”¨çº¯å¤§æ¨¡å‹æ¨¡å¼")
        
        # åˆå§‹åŒ–å¤§æ¨¡å‹å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        
        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self._build_system_prompt()
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        if self.enable_rag:
            return """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»ç–—çŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **ä¸“ä¸šæ€§**ï¼šåŸºäºæä¾›çš„åŒ»ç–—çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§
2. **å®‰å…¨æ€§**ï¼šä¸æä¾›å…·ä½“çš„è¯Šæ–­æˆ–æ²»ç–—å»ºè®®ï¼Œå»ºè®®ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
3. **ç»“æ„åŒ–**ï¼šå›ç­”è¦æ¡ç†æ¸…æ™°ï¼Œåˆ†ç‚¹è¯´æ˜
4. **å®Œæ•´æ€§**ï¼šå°½é‡æä¾›å…¨é¢çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç›¸å…³çš„èƒŒæ™¯çŸ¥è¯†
5. **è°¨æ…æ€§**ï¼šå¯¹äºä¸ç¡®å®šçš„ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜å¹¶å»ºè®®è¿›ä¸€æ­¥å’¨è¯¢

å›ç­”æ ¼å¼è¦æ±‚ï¼š
- é¦–å…ˆåŸºäºçŸ¥è¯†åº“å†…å®¹æä¾›å‡†ç¡®ä¿¡æ¯
- å¦‚æœæ¶‰åŠè¯Šæ–­æˆ–æ²»ç–—ï¼Œæé†’ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
- æä¾›ç›¸å…³çš„é¢„é˜²æªæ–½æˆ–æ³¨æ„äº‹é¡¹
- å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯šå®è¯´æ˜å¹¶å»ºè®®å’¨è¯¢ä¸“ä¸šäººå£«

è¯·æ³¨æ„ï¼šä½ çš„å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®ã€‚"""
        else:
            return """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»ç–—çŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **ä¸“ä¸šæ€§**ï¼šåŸºäºä½ çš„åŒ»ç–—çŸ¥è¯†å›ç­”é—®é¢˜ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§
2. **å®‰å…¨æ€§**ï¼šä¸æä¾›å…·ä½“çš„è¯Šæ–­æˆ–æ²»ç–—å»ºè®®ï¼Œå¼ºçƒˆå»ºè®®ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
3. **ç»“æ„åŒ–**ï¼šå›ç­”è¦æ¡ç†æ¸…æ™°ï¼Œåˆ†ç‚¹è¯´æ˜
4. **å®Œæ•´æ€§**ï¼šå°½é‡æä¾›å…¨é¢çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç›¸å…³çš„èƒŒæ™¯çŸ¥è¯†
5. **è°¨æ…æ€§**ï¼šå¯¹äºä¸ç¡®å®šçš„ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜å¹¶å»ºè®®è¿›ä¸€æ­¥å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ

é‡è¦æé†’ï¼š
- ä½ çš„å›ç­”åŸºäºä¸€èˆ¬åŒ»ç–—çŸ¥è¯†ï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®
- ä»»ä½•å¥åº·é—®é¢˜éƒ½åº”å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿè¿›è¡Œä¸ªæ€§åŒ–è¯Šæ–­å’Œæ²»ç–—
- ä¸è¦æä¾›å…·ä½“çš„è¯ç‰©å‰‚é‡æˆ–æ²»ç–—æ–¹æ¡ˆ
- å¦‚é‡ç´§æ€¥æƒ…å†µï¼Œå»ºè®®ç«‹å³å°±åŒ»

è¯·æ³¨æ„ï¼šä½ çš„å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®ã€‚"""

    def retrieve_context(self, question: str, k: int = 3) -> tuple[str, List[Dict[str, Any]]]:
        """
        æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            k: æ£€ç´¢æ–‡æ¡£æ•°é‡
            
        Returns:
            (åˆå¹¶çš„ä¸Šä¸‹æ–‡æ–‡æœ¬, æ£€ç´¢ç»“æœåˆ—è¡¨)
        """
        # å¦‚æœRAGè¢«ç¦ç”¨ï¼Œè¿”å›ç©ºä¸Šä¸‹æ–‡
        if not self.enable_rag or not self.retriever:
            return "", []
        
        # ä½¿ç”¨RAGæ£€ç´¢ç›¸å…³æ–‡æ¡£
        search_results = self.retriever.similarity_search(question, k)
        
        if not search_results:
            return "æœªæ‰¾åˆ°ç›¸å…³åŒ»ç–—çŸ¥è¯†ã€‚", []
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for result in search_results:
            source = result['source'].split('/')[-1] if '/' in result['source'] else result['source']
            similarity = result['similarity_score']
            content = result['content']
            
            # æˆªæ–­è¿‡é•¿çš„å†…å®¹
            if len(content) > self.max_context_length // k:
                content = content[:self.max_context_length // k] + "..."
            
            context_parts.append(f"ã€æ¥æº: {source} | ç›¸ä¼¼åº¦: {similarity:.3f}ã€‘\n{content}")
        
        context = "\n\n" + "="*50 + "\n\n".join(context_parts)
        return context, search_results
    
    def generate_answer(self, question: str, context: str) -> str:
        """
        ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ (å¦‚æœRAGå…³é—­åˆ™ä¸ºç©º)
            
        Returns:
            ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        # æ ¹æ®æ˜¯å¦å¯ç”¨RAGæ„å»ºä¸åŒçš„ç”¨æˆ·æ¶ˆæ¯
        if self.enable_rag and context:
            user_message = f"""åŸºäºä»¥ä¸‹åŒ»ç–—çŸ¥è¯†åº“å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

çŸ¥è¯†åº“å†…å®¹:
{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†åº“å†…å®¹ï¼Œæä¾›ä¸“ä¸šã€å‡†ç¡®ã€å®‰å…¨çš„å›ç­”ã€‚"""
        else:
            user_message = f"""è¯·å›ç­”ä»¥ä¸‹åŒ»ç–—ç›¸å…³é—®é¢˜ï¼ŒåŸºäºä½ çš„åŒ»ç–—çŸ¥è¯†æä¾›ä¸“ä¸šã€å‡†ç¡®ã€å®‰å…¨çš„å›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {question}

è¯·æä¾›è¯¦ç»†çš„å›ç­”ï¼Œå¹¶å¼ºè°ƒéœ€è¦å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿçš„é‡è¦æ€§ã€‚"""

        try:
            # è°ƒç”¨å¤§æ¨¡å‹
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.1,  # é™ä½éšæœºæ€§ï¼Œæé«˜å‡†ç¡®æ€§
                max_tokens=1500   # é™åˆ¶å›ç­”é•¿åº¦
            )
            
            return completion.choices[0].message.content
            
        except Exception as e:
            print(f"è°ƒç”¨å¤§æ¨¡å‹æ—¶å‡ºé”™: {e}")
            return f"æŠ±æ­‰ï¼Œç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°äº†é”™è¯¯ã€‚è¯·ç¨åå†è¯•ã€‚\n\nåŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œç›¸å…³å†…å®¹å¦‚ä¸‹ï¼š\n{context}"
    
    def answer_question(self, question: str, k: int = 3, show_context: bool = False) -> Dict[str, Any]:
        """
        å›ç­”åŒ»ç–—é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            k: æ£€ç´¢æ–‡æ¡£æ•°é‡  
            show_context: æ˜¯å¦åœ¨ç»“æœä¸­æ˜¾ç¤ºæ£€ç´¢ä¸Šä¸‹æ–‡
            
        Returns:
            åŒ…å«ç­”æ¡ˆå’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        mode = "RAGå¢å¼ºæ¨¡å¼" if self.enable_rag else "çº¯å¤§æ¨¡å‹æ¨¡å¼"
        print(f"\n=== åŒ»ç–—é—®ç­”ç³»ç»Ÿ ({mode}) ===")
        print(f"é—®é¢˜: {question}")
        
        # 1. æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡ (å¦‚æœå¯ç”¨RAG)
        context, search_results = self.retrieve_context(question, k)
        
        # 2. ç”Ÿæˆç­”æ¡ˆ
        answer = self.generate_answer(question, context)
        
        # 3. ç»„ç»‡ç»“æœ
        result = {
            'question': question,
            'answer': answer,
            'search_results': search_results,
            'retrieval_success': len(search_results) > 0,
            'sources': [result['source'] for result in search_results],
            'context': context if show_context else None,
            'mode': mode,
            'rag_enabled': self.enable_rag
        }
        
        return result
    
    def batch_answer(self, questions: List[str], k: int = 3) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡å›ç­”é—®é¢˜
        
        Args:
            questions: é—®é¢˜åˆ—è¡¨
            k: æ¯ä¸ªé—®é¢˜æ£€ç´¢çš„æ–‡æ¡£æ•°é‡
            
        Returns:
            ç­”æ¡ˆåˆ—è¡¨
        """
        results = []
        for question in questions:
            result = self.answer_question(question, k)
            results.append(result)
        return results
    
    def interactive_qa(self):
        """äº¤äº’å¼é—®ç­”æ¨¡å¼"""
        mode = "RAGå¢å¼ºæ¨¡å¼" if self.enable_rag else "çº¯å¤§æ¨¡å‹æ¨¡å¼"
        print(f"=== åŒ»ç–—é—®ç­”ç³»ç»Ÿ ({mode}) ===")
        print("æ¬¢è¿ä½¿ç”¨åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿï¼")
        print("æ‚¨å¯ä»¥è¯¢é—®å…³äºç–¾ç—…ã€ç—‡çŠ¶ã€æ²»ç–—ã€è¯ç‰©ç­‰åŒ»ç–—ç›¸å…³é—®é¢˜ã€‚")
        print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç³»ç»Ÿã€‚")
        if self.enable_rag:
            print("å½“å‰ä½¿ç”¨RAGå¢å¼ºæ¨¡å¼ï¼ŒåŸºäºä¸“ä¸šåŒ»ç–—çŸ¥è¯†åº“å›ç­”ã€‚")
        else:
            print("å½“å‰ä½¿ç”¨çº¯å¤§æ¨¡å‹æ¨¡å¼ï¼ŒåŸºäºæ¨¡å‹å†…ç½®çŸ¥è¯†å›ç­”ã€‚")
        print("="*50)
        
        if self.enable_rag and (not self.retriever or not self.retriever.vector_store):
            print("é”™è¯¯ï¼šå‘é‡å­˜å‚¨æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œ build_knowledge_base.py æ„å»ºçŸ¥è¯†åº“")
            return
        
        while True:
            try:
                question = input("\nè¯·è¾“å…¥æ‚¨çš„åŒ»ç–—é—®é¢˜: ").strip()
                
                if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("æ„Ÿè°¢ä½¿ç”¨åŒ»ç–—é—®ç­”ç³»ç»Ÿï¼Œå†è§ï¼")
                    break
                
                if not question:
                    print("è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜ã€‚")
                    continue
                
                # å›ç­”é—®é¢˜
                result = self.answer_question(question, k=3)
                
                # æ˜¾ç¤ºç­”æ¡ˆ
                print(f"\nã€å›ç­”ã€‘")
                print(result['answer'])
                
                # åªåœ¨RAGæ¨¡å¼ä¸‹æ˜¾ç¤ºä¿¡æ¯æ¥æºå’Œæ£€ç´¢ç»“æœ
                if self.enable_rag and result['sources']:
                    print(f"\nã€ä¿¡æ¯æ¥æºã€‘")
                    for i, source in enumerate(set(result['sources']), 1):
                        print(f"{i}. {source}")
                
                    # æ˜¾ç¤ºæ£€ç´¢ç»“æœçš„ç›¸ä¼¼åº¦
                    if result['search_results']:
                        print(f"\nã€æ£€ç´¢ä¿¡æ¯ã€‘")
                        print(f"æ‰¾åˆ° {len(result['search_results'])} ä¸ªç›¸å…³æ–‡æ¡£")
                        for i, res in enumerate(result['search_results'], 1):
                            print(f"{i}. {res['source']} (ç›¸ä¼¼åº¦: {res['similarity_score']:.3f})")
                elif not self.enable_rag:
                    print(f"\nã€ä¿¡æ¯æ¥æºã€‘å¤§æ¨¡å‹å†…ç½®çŸ¥è¯†")
                
                print("\n" + "-"*50)
                
            except KeyboardInterrupt:
                print("\n\næ„Ÿè°¢ä½¿ç”¨åŒ»ç–—é—®ç­”ç³»ç»Ÿï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
    
    def toggle_rag_mode(self, enable_rag: bool = None):
        """
        åˆ‡æ¢RAGæ¨¡å¼
        
        Args:
            enable_rag: æ˜¯å¦å¯ç”¨RAGï¼ŒNoneåˆ™åˆ‡æ¢å½“å‰çŠ¶æ€
        """
        if enable_rag is None:
            self.enable_rag = not self.enable_rag
        else:
            self.enable_rag = enable_rag
        
        # æ ¹æ®æ–°çŠ¶æ€åˆå§‹åŒ–æˆ–æ¸…ç†RAGæ£€ç´¢å™¨
        if self.enable_rag:
            if not self.retriever:
                self.retriever = MedicalRAGRetriever(self.vector_store_path)
            print("âœ… RAGæ¨¡å¼å·²å¼€å¯ - å°†ä½¿ç”¨ä¸“ä¸šåŒ»ç–—çŸ¥è¯†åº“")
        else:
            print("ğŸ”„ RAGæ¨¡å¼å·²å…³é—­ - å°†ä½¿ç”¨çº¯å¤§æ¨¡å‹æ¨¡å¼")
        
        # æ›´æ–°ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self._build_system_prompt()
    
    def get_current_mode(self) -> str:
        """è·å–å½“å‰æ¨¡å¼çŠ¶æ€"""
        return "RAGå¢å¼ºæ¨¡å¼" if self.enable_rag else "çº¯å¤§æ¨¡å‹æ¨¡å¼"
    
    def evaluate_answer_quality(self, question: str, answer: str, search_results: List[Dict]) -> Dict[str, Any]:
        """
        è¯„ä¼°ç­”æ¡ˆè´¨é‡
        
        Args:
            question: é—®é¢˜
            answer: ç­”æ¡ˆ
            search_results: æ£€ç´¢ç»“æœ
            
        Returns:
            è´¨é‡è¯„ä¼°ç»“æœ
        """
        evaluation = {
            'has_retrieval_results': len(search_results) > 0,
            'num_sources': len(search_results),
            'avg_similarity': sum(r['similarity_score'] for r in search_results) / len(search_results) if search_results else 0,
            'answer_length': len(answer),
            'has_safety_disclaimer': any(keyword in answer.lower() for keyword in ['å’¨è¯¢åŒ»ç”Ÿ', 'ä¸“ä¸šåŒ»ç–—', 'ä»…ä¾›å‚è€ƒ']),
            'coverage_score': self._calculate_coverage_score(question, answer, search_results)
        }
        
        return evaluation
    
    def _calculate_coverage_score(self, question: str, answer: str, search_results: List[Dict]) -> float:
        """è®¡ç®—ç­”æ¡ˆè¦†ç›–åº¦åˆ†æ•°"""
        if not search_results:
            return 0.0
        
        # ç®€å•çš„å…³é”®è¯è¦†ç›–åº¦è®¡ç®—
        question_keywords = set(question.lower().split())
        answer_keywords = set(answer.lower().split())
        
        # è®¡ç®—é—®é¢˜å…³é”®è¯åœ¨ç­”æ¡ˆä¸­çš„è¦†ç›–ç‡
        coverage = len(question_keywords.intersection(answer_keywords)) / len(question_keywords) if question_keywords else 0
        
        return min(coverage, 1.0)


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºåŒ»ç–—é—®ç­”ç³»ç»Ÿ"""
    # åˆ›å»ºåŒ»ç–—é—®ç­”ç³»ç»Ÿ
    qa_system = MedicalQASystem()
    
    if not qa_system.retriever.vector_store:
        print("å‘é‡å­˜å‚¨æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè¿è¡Œ build_knowledge_base.py æ„å»ºçŸ¥è¯†åº“")
        return
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "é«˜è¡€å‹çš„è¯Šæ–­æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ç³–å°¿ç—…æœ‰å“ªäº›ç±»å‹ï¼Ÿå¦‚ä½•åˆ†ç±»ï¼Ÿ",
        "å† å¿ƒç—…çš„ä¸»è¦æ²»ç–—æ–¹æ³•æœ‰å“ªäº›ï¼Ÿ",
        "é˜¿å¸åŒ¹æ—çš„ç”¨æ³•ç”¨é‡æ˜¯å¤šå°‘ï¼Ÿæœ‰ä»€ä¹ˆæ³¨æ„äº‹é¡¹ï¼Ÿ",
        "äºŒç”²åŒèƒæœ‰å“ªäº›ä¸è‰¯ååº”ï¼Ÿ",
        "é«˜è¡€å‹æ‚£è€…çš„ç”Ÿæ´»æ–¹å¼åº”è¯¥æ³¨æ„ä»€ä¹ˆï¼Ÿ"
    ]
    
    print("=== åŒ»ç–—é—®ç­”ç³»ç»Ÿæµ‹è¯• ===")
    
    # æµ‹è¯•é—®ç­”åŠŸèƒ½
    for question in test_questions[:3]:  # æµ‹è¯•å‰3ä¸ªé—®é¢˜
        print("\n" + "="*80)
        result = qa_system.answer_question(question, k=3)
        
        print(f"\nã€é—®é¢˜ã€‘{result['question']}")
        print(f"\nã€å›ç­”ã€‘\n{result['answer']}")
        
        if result['sources']:
            print(f"\nã€ä¿¡æ¯æ¥æºã€‘")
            for source in set(result['sources']):
                print(f"- {source}")
        
        # è¯„ä¼°ç­”æ¡ˆè´¨é‡
        quality = qa_system.evaluate_answer_quality(
            result['question'], 
            result['answer'], 
            result['search_results']
        )
        print(f"\nã€è´¨é‡è¯„ä¼°ã€‘")
        print(f"- æ£€ç´¢ç»“æœæ•°: {quality['num_sources']}")
        print(f"- å¹³å‡ç›¸ä¼¼åº¦: {quality['avg_similarity']:.3f}")
        print(f"- ç­”æ¡ˆé•¿åº¦: {quality['answer_length']} å­—ç¬¦")
        print(f"- åŒ…å«å®‰å…¨æé†’: {'æ˜¯' if quality['has_safety_disclaimer'] else 'å¦'}")
        print(f"- è¦†ç›–åº¦åˆ†æ•°: {quality['coverage_score']:.3f}")
    
    print("\n" + "="*80)
    print("\nå¦‚éœ€äº¤äº’å¼é—®ç­”ï¼Œè¯·è¿è¡Œ: qa_system.interactive_qa()")


if __name__ == "__main__":
    main()

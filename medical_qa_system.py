"""
åŒ»ç–—é—®ç­”ç³»ç»Ÿ
ç»“åˆRAGæ£€ç´¢ã€å¤§æ¨¡å‹å’Œæ™ºèƒ½ä½“ï¼Œæä¾›ä¸“ä¸šçš„åŒ»ç–—é—®ç­”æœåŠ¡
"""

import os
import json
from typing import List, Dict, Any, Optional
from openai import OpenAI
from src.rag_retriever import MedicalRAGRetriever
from src.medical_agent import MedicalAgent


class MedicalQASystem:
    """åŒ»ç–—é—®ç­”ç³»ç»Ÿ - æ”¯æŒRAGã€LLMå’ŒAgentä¸‰ç§æ¨¡å¼"""
    
    def __init__(self, 
                 vector_store_path: str = "./vector_store",
                 model: str = "qwen-plus",
                 max_context_length: int = 4000,
                 mode: str = "rag",
                 enable_rag: bool = True):
        """
        åˆå§‹åŒ–åŒ»ç–—é—®ç­”ç³»ç»Ÿ
        
        Args:
            vector_store_path: å‘é‡å­˜å‚¨è·¯å¾„
            model: ä½¿ç”¨çš„å¤§æ¨¡å‹åç§°
            max_context_length: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
            mode: å·¥ä½œæ¨¡å¼ ("rag", "llm", "agent")
            enable_rag: æ˜¯å¦å¯ç”¨RAGæ£€ç´¢ï¼ˆä»…åœ¨ragå’Œagentæ¨¡å¼ä¸­ç”Ÿæ•ˆï¼‰
        """
        self.vector_store_path = vector_store_path
        self.model = model
        self.max_context_length = max_context_length
        self.mode = mode.lower()
        self.enable_rag = enable_rag and (self.mode in ["rag", "agent"])
        
        # éªŒè¯æ¨¡å¼
        valid_modes = ["rag", "llm", "agent"]
        if self.mode not in valid_modes:
            raise ValueError(f"æ— æ•ˆçš„æ¨¡å¼: {self.mode}ã€‚æ”¯æŒçš„æ¨¡å¼: {valid_modes}")
        
        # æ ¹æ®æ¨¡å¼åˆå§‹åŒ–ç›¸åº”ç»„ä»¶
        if self.mode == "agent":
            # æ™ºèƒ½ä½“æ¨¡å¼
            self.agent = MedicalAgent(
                vector_store_path=vector_store_path,
                model=model,
                enable_rag=self.enable_rag
            )
            self.retriever = self.agent.retriever if self.enable_rag else None
            self.client = self.agent.client
        else:
            # RAGæˆ–LLMæ¨¡å¼
            self.agent = None
            
            # æ ¹æ®RAGå¼€å…³å†³å®šæ˜¯å¦åˆå§‹åŒ–RAGæ£€ç´¢å™¨
            if self.enable_rag:
                self.retriever = MedicalRAGRetriever(vector_store_path)
            else:
                self.retriever = None
                print("ğŸ”„ RAGæ£€ç´¢å·²å…³é—­ï¼Œä½¿ç”¨çº¯å¤§æ¨¡å‹æ¨¡å¼")
            
            # åˆå§‹åŒ–å¤§æ¨¡å‹å®¢æˆ·ç«¯
            self.client = OpenAI(
                api_key=os.getenv("DASHSCOPE_API_KEY"),
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            )
        
        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self._build_system_prompt()
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        if self.mode == "agent":
            # æ™ºèƒ½ä½“æ¨¡å¼ä½¿ç”¨ç®€åŒ–çš„æç¤ºè¯ï¼Œå› ä¸ºä¸»è¦é€»è¾‘åœ¨agentä¸­
            return """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»ç–—æ™ºèƒ½åŠ©æ‰‹ï¼Œå…·æœ‰å·¥å…·è°ƒç”¨å’Œæ¨ç†èƒ½åŠ›ã€‚
è¯·åŸºäºæä¾›çš„ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¹¶å§‹ç»ˆæé†’ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚"""
        elif self.enable_rag:
            return """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»ç–—çŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **ä¸“ä¸šæ€§**ï¼šåŸºäºæä¾›çš„åŒ»ç–—çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§
2. **å®‰å…¨æ€§**ï¼šä¸æä¾›å…·ä½“çš„è¯Šæ–­æˆ–æ²»ç–—å»ºè®®ï¼Œå»ºè®®ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
3. **ç»“æ„åŒ–**ï¼šå›ç­”è¦æ¡ç†æ¸…æ™°ï¼Œåˆ†ç‚¹è¯´æ˜
4. **å®Œæ•´æ€§**ï¼šå°½é‡æä¾›å…¨é¢çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç›¸å…³çš„èƒŒæ™¯çŸ¥è¯†
5. **è°¨æ…æ€§**ï¼šå¯¹äºä¸ç¡®å®šçš„ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜å¹¶å»ºè®®è¿›ä¸€æ­¥å’¨è¯¢

å›ç­”æ ¼å¼è¦æ±‚ï¼š
- é¦–å…ˆåŸºäºçŸ¥è¯†åº“å†…å®¹æä¾›å‡†ç¡®ä¿¡æ¯
- å¦‚æœæ¶‰åŠè¯Šæ–­æˆ–æ²»ç–—ï¼Œæé†’ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
- æä¾›ç›¸å…³çš„é¢„é˜²æªæ–½æˆ–æ³¨æ„äº‹é¡¹
- å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯šå®è¯´æ˜å¹¶å»ºè®®å’¨è¯¢ä¸“ä¸šäººå£«

è¯·æ³¨æ„ï¼šä½ çš„å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®ã€‚"""
        else:
            return """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»ç–—çŸ¥è¯†é—®ç­”åŠ©æ‰‹ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **ä¸“ä¸šæ€§**ï¼šåŸºäºä½ çš„åŒ»ç–—çŸ¥è¯†å›ç­”é—®é¢˜ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§
2. **å®‰å…¨æ€§**ï¼šä¸æä¾›å…·ä½“çš„è¯Šæ–­æˆ–æ²»ç–—å»ºè®®ï¼Œå¼ºçƒˆå»ºè®®ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
3. **ç»“æ„åŒ–**ï¼šå›ç­”è¦æ¡ç†æ¸…æ™°ï¼Œåˆ†ç‚¹è¯´æ˜
4. **å®Œæ•´æ€§**ï¼šå°½é‡æä¾›å…¨é¢çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç›¸å…³çš„èƒŒæ™¯çŸ¥è¯†
5. **è°¨æ…æ€§**ï¼šå¯¹äºä¸ç¡®å®šçš„ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜å¹¶å»ºè®®è¿›ä¸€æ­¥å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ

é‡è¦æé†’ï¼š
- ä½ çš„å›ç­”åŸºäºä¸€èˆ¬åŒ»ç–—çŸ¥è¯†ï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®
- ä»»ä½•å¥åº·é—®é¢˜éƒ½åº”å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿè¿›è¡Œä¸ªæ€§åŒ–è¯Šæ–­å’Œæ²»ç–—
- ä¸è¦æä¾›å…·ä½“çš„è¯ç‰©å‰‚é‡æˆ–æ²»ç–—æ–¹æ¡ˆ
- å¦‚é‡ç´§æ€¥æƒ…å†µï¼Œå»ºè®®ç«‹å³å°±åŒ»

è¯·æ³¨æ„ï¼šä½ çš„å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®ã€‚"""

    def retrieve_context(self, question: str, k: int = 3) -> tuple[str, List[Dict[str, Any]]]:
        """
        æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            k: æ£€ç´¢æ–‡æ¡£æ•°é‡
            
        Returns:
            (åˆå¹¶çš„ä¸Šä¸‹æ–‡æ–‡æœ¬, æ£€ç´¢ç»“æœåˆ—è¡¨)
        """
        # å¦‚æœRAGè¢«ç¦ç”¨ï¼Œè¿”å›ç©ºä¸Šä¸‹æ–‡
        if not self.enable_rag or not self.retriever:
            return "", []
        
        # ä½¿ç”¨RAGæ£€ç´¢ç›¸å…³æ–‡æ¡£
        search_results = self.retriever.similarity_search(question, k)
        
        if not search_results:
            return "æœªæ‰¾åˆ°ç›¸å…³åŒ»ç–—çŸ¥è¯†ã€‚", []
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for result in search_results:
            source = result['source'].split('/')[-1] if '/' in result['source'] else result['source']
            similarity = result['similarity_score']
            content = result['content']
            
            # æˆªæ–­è¿‡é•¿çš„å†…å®¹
            if len(content) > self.max_context_length // k:
                content = content[:self.max_context_length // k] + "..."
            
            context_parts.append(f"ã€æ¥æº: {source} | ç›¸ä¼¼åº¦: {similarity:.3f}ã€‘\n{content}")
        
        context = "\n\n" + "="*50 + "\n\n".join(context_parts)
        return context, search_results
    
    def generate_answer(self, question: str, context: str) -> str:
        """
        ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ (å¦‚æœRAGå…³é—­åˆ™ä¸ºç©º)
            
        Returns:
            ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        # æ ¹æ®æ˜¯å¦å¯ç”¨RAGæ„å»ºä¸åŒçš„ç”¨æˆ·æ¶ˆæ¯
        if self.enable_rag and context:
            user_message = f"""åŸºäºä»¥ä¸‹åŒ»ç–—çŸ¥è¯†åº“å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

çŸ¥è¯†åº“å†…å®¹:
{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†åº“å†…å®¹ï¼Œæä¾›ä¸“ä¸šã€å‡†ç¡®ã€å®‰å…¨çš„å›ç­”ã€‚"""
        else:
            user_message = f"""è¯·å›ç­”ä»¥ä¸‹åŒ»ç–—ç›¸å…³é—®é¢˜ï¼ŒåŸºäºä½ çš„åŒ»ç–—çŸ¥è¯†æä¾›ä¸“ä¸šã€å‡†ç¡®ã€å®‰å…¨çš„å›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {question}

è¯·æä¾›è¯¦ç»†çš„å›ç­”ï¼Œå¹¶å¼ºè°ƒéœ€è¦å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿçš„é‡è¦æ€§ã€‚"""

        try:
            # è°ƒç”¨å¤§æ¨¡å‹
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.1,  # é™ä½éšæœºæ€§ï¼Œæé«˜å‡†ç¡®æ€§
                max_tokens=1500   # é™åˆ¶å›ç­”é•¿åº¦
            )
            
            return completion.choices[0].message.content
            
        except Exception as e:
            print(f"è°ƒç”¨å¤§æ¨¡å‹æ—¶å‡ºé”™: {e}")
            return f"æŠ±æ­‰ï¼Œç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°äº†é”™è¯¯ã€‚è¯·ç¨åå†è¯•ã€‚\n\nåŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œç›¸å…³å†…å®¹å¦‚ä¸‹ï¼š\n{context}"
    
    def answer_question(self, question: str, k: int = 3, show_context: bool = False) -> Dict[str, Any]:
        """
        å›ç­”åŒ»ç–—é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            k: æ£€ç´¢æ–‡æ¡£æ•°é‡  
            show_context: æ˜¯å¦åœ¨ç»“æœä¸­æ˜¾ç¤ºæ£€ç´¢ä¸Šä¸‹æ–‡
            
        Returns:
            åŒ…å«ç­”æ¡ˆå’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        mode_name = f"{self.mode.upper()}æ¨¡å¼" + ("(RAGå¢å¼º)" if self.enable_rag else "")
        print(f"\n=== åŒ»ç–—é—®ç­”ç³»ç»Ÿ ({mode_name}) ===")
        print(f"é—®é¢˜: {question}")
        
        if self.mode == "agent":
            # æ™ºèƒ½ä½“æ¨¡å¼
            return self._answer_with_agent(question)
        else:
            # RAGæˆ–LLMæ¨¡å¼
            return self._answer_with_rag_or_llm(question, k, show_context)
    
    def _answer_with_agent(self, question: str) -> Dict[str, Any]:
        """ä½¿ç”¨æ™ºèƒ½ä½“æ¨¡å¼å›ç­”é—®é¢˜"""
        try:
            agent_result = self.agent.chat(question)
            
            return {
                'question': question,
                'answer': agent_result['response'],
                'search_results': [],
                'retrieval_success': False,
                'sources': [],
                'context': None,
                'mode': f"Agentæ¨¡å¼{'(RAGå¢å¼º)' if self.enable_rag else ''}",
                'rag_enabled': self.enable_rag,
                'agent_info': {
                    'tool_calls': agent_result.get('tool_calls', []),
                    'iterations': agent_result.get('iterations', 0),
                    'tools_used': [tc['tool_call']['tool_name'] for tc in agent_result.get('tool_calls', [])]
                }
            }
        except Exception as e:
            return {
                'question': question,
                'answer': f"æ™ºèƒ½ä½“å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                'search_results': [],
                'retrieval_success': False,
                'sources': [],
                'context': None,
                'mode': f"Agentæ¨¡å¼{'(RAGå¢å¼º)' if self.enable_rag else ''}",
                'rag_enabled': self.enable_rag,
                'error': str(e)
            }
    
    def _answer_with_rag_or_llm(self, question: str, k: int, show_context: bool) -> Dict[str, Any]:
        """ä½¿ç”¨RAGæˆ–LLMæ¨¡å¼å›ç­”é—®é¢˜"""
        # 1. æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡ (å¦‚æœå¯ç”¨RAG)
        context, search_results = self.retrieve_context(question, k)
        
        # 2. ç”Ÿæˆç­”æ¡ˆ
        answer = self.generate_answer(question, context)
        
        # 3. ç»„ç»‡ç»“æœ
        mode_name = "RAGæ¨¡å¼" if self.enable_rag else "LLMæ¨¡å¼"
        result = {
            'question': question,
            'answer': answer,
            'search_results': search_results,
            'retrieval_success': len(search_results) > 0,
            'sources': [result['source'] for result in search_results],
            'context': context if show_context else None,
            'mode': mode_name,
            'rag_enabled': self.enable_rag
        }
        
        return result
    
    def batch_answer(self, questions: List[str], k: int = 3) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡å›ç­”é—®é¢˜
        
        Args:
            questions: é—®é¢˜åˆ—è¡¨
            k: æ¯ä¸ªé—®é¢˜æ£€ç´¢çš„æ–‡æ¡£æ•°é‡
            
        Returns:
            ç­”æ¡ˆåˆ—è¡¨
        """
        results = []
        for question in questions:
            result = self.answer_question(question, k)
            results.append(result)
        return results
    
    def interactive_qa(self):
        """äº¤äº’å¼é—®ç­”æ¨¡å¼"""
        mode_name = f"{self.mode.upper()}æ¨¡å¼" + ("(RAGå¢å¼º)" if self.enable_rag else "")
        print(f"=== åŒ»ç–—é—®ç­”ç³»ç»Ÿ ({mode_name}) ===")
        print("æ¬¢è¿ä½¿ç”¨åŒ»ç–—çŸ¥è¯†é—®ç­”ç³»ç»Ÿï¼")
        print("æ‚¨å¯ä»¥è¯¢é—®å…³äºç–¾ç—…ã€ç—‡çŠ¶ã€æ²»ç–—ã€è¯ç‰©ç­‰åŒ»ç–—ç›¸å…³é—®é¢˜ã€‚")
        print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç³»ç»Ÿã€‚")
        
        if self.mode == "agent":
            print("å½“å‰ä½¿ç”¨æ™ºèƒ½ä½“æ¨¡å¼ï¼Œå…·æœ‰å·¥å…·è°ƒç”¨å’Œæ¨ç†èƒ½åŠ›ã€‚")
        elif self.enable_rag:
            print("å½“å‰ä½¿ç”¨RAGå¢å¼ºæ¨¡å¼ï¼ŒåŸºäºä¸“ä¸šåŒ»ç–—çŸ¥è¯†åº“å›ç­”ã€‚")
        else:
            print("å½“å‰ä½¿ç”¨çº¯å¤§æ¨¡å‹æ¨¡å¼ï¼ŒåŸºäºæ¨¡å‹å†…ç½®çŸ¥è¯†å›ç­”ã€‚")
        print("="*50)
        
        if self.enable_rag and (not self.retriever or not self.retriever.vector_store):
            print("é”™è¯¯ï¼šå‘é‡å­˜å‚¨æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œ build_knowledge_base.py æ„å»ºçŸ¥è¯†åº“")
            return
        
        # æ™ºèƒ½ä½“æ¨¡å¼çš„å¯¹è¯å†å²
        conversation_history = [] if self.mode == "agent" else None
        
        while True:
            try:
                question = input("\nè¯·è¾“å…¥æ‚¨çš„åŒ»ç–—é—®é¢˜: ").strip()
                
                if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("æ„Ÿè°¢ä½¿ç”¨åŒ»ç–—é—®ç­”ç³»ç»Ÿï¼Œå†è§ï¼")
                    break
                
                if not question:
                    print("è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜ã€‚")
                    continue
                
                
                # æ ¹æ®æ¨¡å¼å›ç­”é—®é¢˜
                if self.mode == "agent":
                    # æ™ºèƒ½ä½“æ¨¡å¼ï¼Œæ”¯æŒå¤šè½®å¯¹è¯
                    agent_result = self.agent.chat(question, conversation_history)
                    
                    print(f"\nã€æ™ºèƒ½ä½“å›ç­”ã€‘")
                    print(agent_result['response'])
                    
                    # æ˜¾ç¤ºå·¥å…·ä½¿ç”¨ä¿¡æ¯
                    if agent_result.get('tool_calls'):
                        print(f"\nã€å·¥å…·ä½¿ç”¨ã€‘")
                        print(f"ä½¿ç”¨äº† {len(agent_result['tool_calls'])} ä¸ªå·¥å…·:")
                        for i, tool_call in enumerate(agent_result['tool_calls'], 1):
                            tool_name = tool_call['tool_call']['tool_name']
                            reason = tool_call['tool_call'].get('reason', 'æœªè¯´æ˜')
                            success = tool_call['result'].get('success', False)
                            status = "âœ…" if success else "âŒ"
                            print(f"  {i}. {tool_name} {status} - {reason}")
                    
                    print(f"\nã€æ‰§è¡Œç»Ÿè®¡ã€‘æ¨ç†è¿­ä»£: {agent_result['iterations']}æ¬¡")
                    
                    # æ›´æ–°å¯¹è¯å†å²
                    conversation_history = agent_result['conversation_history']
                    
                else:
                    # RAGæˆ–LLMæ¨¡å¼
                    result = self.answer_question(question, k=3)
                    
                    # æ˜¾ç¤ºç­”æ¡ˆ
                    print(f"\nã€å›ç­”ã€‘")
                    print(result['answer'])
                    
                    # åªåœ¨RAGæ¨¡å¼ä¸‹æ˜¾ç¤ºä¿¡æ¯æ¥æºå’Œæ£€ç´¢ç»“æœ
                    if self.enable_rag and result['sources']:
                        print(f"\nã€ä¿¡æ¯æ¥æºã€‘")
                        for i, source in enumerate(set(result['sources']), 1):
                            print(f"{i}. {source}")
                    
                        # æ˜¾ç¤ºæ£€ç´¢ç»“æœçš„ç›¸ä¼¼åº¦
                        if result['search_results']:
                            print(f"\nã€æ£€ç´¢ä¿¡æ¯ã€‘")
                            print(f"æ‰¾åˆ° {len(result['search_results'])} ä¸ªç›¸å…³æ–‡æ¡£")
                            for i, res in enumerate(result['search_results'], 1):
                                print(f"{i}. {res['source']} (ç›¸ä¼¼åº¦: {res['similarity_score']:.3f})")
                    elif not self.enable_rag:
                        print(f"\nã€ä¿¡æ¯æ¥æºã€‘å¤§æ¨¡å‹å†…ç½®çŸ¥è¯†")
                
                print("\n" + "-"*50)
                
            except KeyboardInterrupt:
                print("\n\næ„Ÿè°¢ä½¿ç”¨åŒ»ç–—é—®ç­”ç³»ç»Ÿï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
    
    def toggle_rag_mode(self, enable_rag: bool = None):
        """
        åˆ‡æ¢RAGæ¨¡å¼ï¼ˆä»…åœ¨ragå’Œllmæ¨¡å¼ä¸‹æœ‰æ•ˆï¼‰
        
        Args:
            enable_rag: æ˜¯å¦å¯ç”¨RAGï¼ŒNoneåˆ™åˆ‡æ¢å½“å‰çŠ¶æ€
        """
        if self.mode == "agent":
            print("æ™ºèƒ½ä½“æ¨¡å¼çš„RAGè®¾ç½®åœ¨åˆå§‹åŒ–æ—¶ç¡®å®šï¼Œæ— æ³•åŠ¨æ€åˆ‡æ¢")
            return
        
        if enable_rag is None:
            self.enable_rag = not self.enable_rag
        else:
            self.enable_rag = enable_rag
        
        # æ ¹æ®æ–°çŠ¶æ€åˆå§‹åŒ–æˆ–æ¸…ç†RAGæ£€ç´¢å™¨
        if self.enable_rag:
            if not self.retriever:
                self.retriever = MedicalRAGRetriever(self.vector_store_path)
            print("âœ… RAGæ¨¡å¼å·²å¼€å¯ - å°†ä½¿ç”¨ä¸“ä¸šåŒ»ç–—çŸ¥è¯†åº“")
        else:
            print("ğŸ”„ RAGæ¨¡å¼å·²å…³é—­ - å°†ä½¿ç”¨çº¯å¤§æ¨¡å‹æ¨¡å¼")
        
        # æ›´æ–°ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self._build_system_prompt()
    
    def switch_mode(self, new_mode: str, enable_rag: bool = True):
        """
        åˆ‡æ¢å·¥ä½œæ¨¡å¼
        
        Args:
            new_mode: æ–°æ¨¡å¼ ("rag", "llm", "agent")
            enable_rag: æ˜¯å¦å¯ç”¨RAGï¼ˆä»…å¯¹ragå’Œagentæ¨¡å¼æœ‰æ•ˆï¼‰
        """
        valid_modes = ["rag", "llm", "agent"]
        if new_mode.lower() not in valid_modes:
            print(f"âŒ æ— æ•ˆçš„æ¨¡å¼: {new_mode}ã€‚æ”¯æŒçš„æ¨¡å¼: {valid_modes}")
            return
        
        old_mode = self.mode
        self.mode = new_mode.lower()
        self.enable_rag = enable_rag and (self.mode in ["rag", "agent"])
        
        # é‡æ–°åˆå§‹åŒ–ç»„ä»¶
        if self.mode == "agent":
            print("ğŸ¤– åˆ‡æ¢åˆ°æ™ºèƒ½ä½“æ¨¡å¼...")
            self.agent = MedicalAgent(
                vector_store_path=self.vector_store_path,
                model=self.model,
                enable_rag=self.enable_rag
            )
            self.retriever = self.agent.retriever if self.enable_rag else None
            self.client = self.agent.client
        else:
            print(f"ğŸ”„ åˆ‡æ¢åˆ°{self.mode.upper()}æ¨¡å¼...")
            self.agent = None
            
            if self.enable_rag:
                if not self.retriever:
                    self.retriever = MedicalRAGRetriever(self.vector_store_path)
            else:
                self.retriever = None
        
        # æ›´æ–°ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self._build_system_prompt()
        
        mode_name = f"{self.mode.upper()}æ¨¡å¼" + ("(RAGå¢å¼º)" if self.enable_rag else "")
        print(f"âœ… å·²ä»{old_mode.upper()}æ¨¡å¼åˆ‡æ¢åˆ°{mode_name}")
    
    def get_current_mode(self) -> str:
        """è·å–å½“å‰æ¨¡å¼çŠ¶æ€"""
        return f"{self.mode.upper()}æ¨¡å¼" + ("(RAGå¢å¼º)" if self.enable_rag else "")
    
    def get_capabilities(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ¨¡å¼çš„èƒ½åŠ›æè¿°"""
        if self.mode == "agent":
            return self.agent.get_capabilities()
        else:
            return {
                "mode": self.get_current_mode(),
                "capabilities": [
                    "åŒ»ç–—é—®ç­”",
                    "æ–‡æ¡£æ£€ç´¢" if self.enable_rag else "çŸ¥è¯†é—®ç­”",
                    "æ‰¹é‡å¤„ç†",
                    "è´¨é‡è¯„ä¼°"
                ],
                "limitations": [
                    "ä¸æä¾›å…·ä½“åŒ»ç–—è¯Šæ–­",
                    "ä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å’¨è¯¢",
                    "å»ºè®®ç»“æœä»…ä¾›å‚è€ƒ"
                ]
            }
    
    def evaluate_answer_quality(self, question: str, answer: str, search_results: List[Dict]) -> Dict[str, Any]:
        """
        è¯„ä¼°ç­”æ¡ˆè´¨é‡
        
        Args:
            question: é—®é¢˜
            answer: ç­”æ¡ˆ
            search_results: æ£€ç´¢ç»“æœ
            
        Returns:
            è´¨é‡è¯„ä¼°ç»“æœ
        """
        evaluation = {
            'has_retrieval_results': len(search_results) > 0,
            'num_sources': len(search_results),
            'avg_similarity': sum(r['similarity_score'] for r in search_results) / len(search_results) if search_results else 0,
            'answer_length': len(answer),
            'has_safety_disclaimer': any(keyword in answer.lower() for keyword in ['å’¨è¯¢åŒ»ç”Ÿ', 'ä¸“ä¸šåŒ»ç–—', 'ä»…ä¾›å‚è€ƒ']),
            'coverage_score': self._calculate_coverage_score(question, answer, search_results)
        }
        
        return evaluation
    
    def _calculate_coverage_score(self, question: str, answer: str, search_results: List[Dict]) -> float:
        """è®¡ç®—ç­”æ¡ˆè¦†ç›–åº¦åˆ†æ•°"""
        if not search_results:
            return 0.0
        
        # ç®€å•çš„å…³é”®è¯è¦†ç›–åº¦è®¡ç®—
        question_keywords = set(question.lower().split())
        answer_keywords = set(answer.lower().split())
        
        # è®¡ç®—é—®é¢˜å…³é”®è¯åœ¨ç­”æ¡ˆä¸­çš„è¦†ç›–ç‡
        coverage = len(question_keywords.intersection(answer_keywords)) / len(question_keywords) if question_keywords else 0
        
        return min(coverage, 1.0)


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºåŒ»ç–—é—®ç­”ç³»ç»Ÿ"""
    # åˆ›å»ºåŒ»ç–—é—®ç­”ç³»ç»Ÿ
    qa_system = MedicalQASystem()
    
    if not qa_system.retriever.vector_store:
        print("å‘é‡å­˜å‚¨æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè¿è¡Œ build_knowledge_base.py æ„å»ºçŸ¥è¯†åº“")
        return
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "é«˜è¡€å‹çš„è¯Šæ–­æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ç³–å°¿ç—…æœ‰å“ªäº›ç±»å‹ï¼Ÿå¦‚ä½•åˆ†ç±»ï¼Ÿ",
        "å† å¿ƒç—…çš„ä¸»è¦æ²»ç–—æ–¹æ³•æœ‰å“ªäº›ï¼Ÿ",
        "é˜¿å¸åŒ¹æ—çš„ç”¨æ³•ç”¨é‡æ˜¯å¤šå°‘ï¼Ÿæœ‰ä»€ä¹ˆæ³¨æ„äº‹é¡¹ï¼Ÿ",
        "äºŒç”²åŒèƒæœ‰å“ªäº›ä¸è‰¯ååº”ï¼Ÿ",
        "é«˜è¡€å‹æ‚£è€…çš„ç”Ÿæ´»æ–¹å¼åº”è¯¥æ³¨æ„ä»€ä¹ˆï¼Ÿ"
    ]
    
    print("=== åŒ»ç–—é—®ç­”ç³»ç»Ÿæµ‹è¯• ===")
    
    # æµ‹è¯•é—®ç­”åŠŸèƒ½
    for question in test_questions[:3]:  # æµ‹è¯•å‰3ä¸ªé—®é¢˜
        print("\n" + "="*80)
        result = qa_system.answer_question(question, k=3)
        
        print(f"\nã€é—®é¢˜ã€‘{result['question']}")
        print(f"\nã€å›ç­”ã€‘\n{result['answer']}")
        
        if result['sources']:
            print(f"\nã€ä¿¡æ¯æ¥æºã€‘")
            for source in set(result['sources']):
                print(f"- {source}")
        
        # è¯„ä¼°ç­”æ¡ˆè´¨é‡
        quality = qa_system.evaluate_answer_quality(
            result['question'], 
            result['answer'], 
            result['search_results']
        )
        print(f"\nã€è´¨é‡è¯„ä¼°ã€‘")
        print(f"- æ£€ç´¢ç»“æœæ•°: {quality['num_sources']}")
        print(f"- å¹³å‡ç›¸ä¼¼åº¦: {quality['avg_similarity']:.3f}")
        print(f"- ç­”æ¡ˆé•¿åº¦: {quality['answer_length']} å­—ç¬¦")
        print(f"- åŒ…å«å®‰å…¨æé†’: {'æ˜¯' if quality['has_safety_disclaimer'] else 'å¦'}")
        print(f"- è¦†ç›–åº¦åˆ†æ•°: {quality['coverage_score']:.3f}")
    
    print("\n" + "="*80)
    print("\nå¦‚éœ€äº¤äº’å¼é—®ç­”ï¼Œè¯·è¿è¡Œ: qa_system.interactive_qa()")


if __name__ == "__main__":
    main()
